{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "existing-tennis",
   "metadata": {},
   "source": [
    "# Combining the data\n",
    "\n",
    "Use one of the following options to combine data CSVs into a single CSV.\n",
    "\n",
    "**DASK**\n",
    "\n",
    "When combining the csv files make sure to add extra column called \"model\" that identifies the model (tip : you can get this column populated from the file name eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON)\n",
    "\n",
    "Compare run times and memory usages of these options on different machines within your team, and summarize your observations in your milestone notebook.\n",
    "\n",
    "Warning: Some of you might not be able to do it on your laptop. It's fine if you're unable to do it. Just make sure you check memory usage and discuss the reasons why you might not have been able to run this on your laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "skilled-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in libraries\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extra-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.zip\n"
     ]
    }
   ],
   "source": [
    "# Read in data into data directory\n",
    "%run -i '../src/requests.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select column names\n",
    "use_cols = ['time', 'lat_min', 'lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']\n",
    "\n",
    "# Get extension for all files\n",
    "all_files = \"../data/*NSW.csv\"\n",
    "\n",
    "# Combine all files\n",
    "ddf = dd.read_csv(all_files, assume_missing=True, usecols=use_cols, include_path_column=True)\n",
    "\n",
    "# Create model column\n",
    "ddf['model'] = ddf['path'].str.split(\"/\", expand=True, n=10)[10].str.split(\"_\", expand=True, n=3)[0]\n",
    "\n",
    "# Drop path column\n",
    "ddf.drop(['path'], axis=1)\n",
    "\n",
    "# Write combined data to single file\n",
    "ddf.to_csv(\"../data/combined_NSW.csv\", single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-sculpture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
